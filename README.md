# Model Performance Evaluation with Preprocessing
 This project analyzes the impact of various preprocessing techniques on the performance of different machine learning models. The models evaluated include Logistic Regression, K-Nearest Neighbors (KNN), Random Forest, and LSTM.

## Objective
 To compare the classification performance of different models before and after applying preprocessing techniques.

## Preprocessing Techniques
Encoding – Converts categorical data into numerical format.
Feature Selection – Identifies the most relevant features.
SMOTE (Synthetic Minority Over-sampling Technique) – Balances class distribution.
PCA (Principal Component Analysis) – Reduces dimensionality.
Standardization – Normalizes feature values.
# Models Used
Logistic Regression
K-Nearest Neighbors (KNN)
Random Forest
LSTM (Long Short-Term Memory)
##Evaluation Metrics
Each model is assessed based on:

Accuracy
Precision
Recall
F1 Score

# Setup & Usage
Clone the repository.
Install the required dependencies.
Run preprocessing, training, and evaluation scripts in sequence.
# License
This project is licensed under the MIT License.
